[
{
	"uri": "/01-compute/",
	"title": "01 - AWS Compute Services",
	"tags": [],
	"description": "",
	"content": "  Elastic Cloud Compute (EC2)  Instance Profile Instance Metadata Placement Groups Cluster Placement Group (CPG) Partition Placement Group (PPG) Spread Placement Group (SPG) User Data EC2 Pricing On-Demand Reserved Instances Spot Instances Savings Plans Dedicated Hosts  Amazon Machine Image (AMI) Amazon Elastic Block Storage (EBS)  EBS Volume Types  AWS Lambda Amazon Elastic Container Service (ECS) Auto Scaling Groups (ASG)  Elastic Cloud Compute (EC2)  EC2 is a Cloud Computing Service. It is responsible for providing long-running compute as service. Configures your EC2 by choosing your OS, Storage, Memory, Network Throughput EC2 comes in variety Instance types of specialization for different roles [EC2 Families]  General Purpose - Balance of Compute, Memory and Networking resources Compute Optimized - Ideal for compute based application that benefit from high performance processor Memory Optimized - Ideal for fast performance workloads processing large data sets in memory Storage Optimized - Ideal for high sequential, read and write access to very large dataset on local storage Accelerated Optimized - Hardware accelerators, or, co-processors  Instance sizes include Nano, Small, Medium, Large, X.Large, 2X.Large and Larger  Instance Profile  Instance Profiles is a container for an IAM role that you can use to pass role information to an EC2 instance when the instance starts. An instance profile is either created automatically when using the console UI or manually when using the CLI. EC2 instance roles are IAM roles that are \u0026ldquo;assumed\u0026rdquo; by EC2 using intermediary called an Instance Profile.  Instance Metadata  Instance metadata can be used to access information about current instance from the instance. It allows applications running within EC2 to have visibility into their environment. E.g, curl http://169.254.169.254/latest/meta-data provides information about instance type, current ip etc.  Placement Groups  Let you choose the logical placement of your instances to optimize for network, performance or durability Placement groups are free of cost.  Cluster Placement Group (CPG)  Places instances physically near other in a single availability zone It works with Enhanced Networking for delivering maximum performance  Partition Placement Group (PPG)  Instances deployed into a partition placement group are separated into partitions, each occupying isolated rack in AZs It minimizes failure in partition and provides visibility on placement  Spread Placement Group (SPG)  Designed for max of seven (7) instances per AZ Each instance occupies a partition and has an isolated fault domain  User Data  When you launch an instance in Amazon EC2, you have the option of passing User Data to the instance that can be used to perform common automated configuration tasks and even run scripts after the instance starts. You can pass two types of user data to Amazon EC2: shell scripts and cloud-init directives  EC2 Pricing EC2 has 5 pricing models.\nOn-Demand  Pay for EC2 instances you use (Flexible) Pay per hour or second(Minimum of 60 sec)] Ideal when work-load cannot be interrupted The use of On-Demand instances frees you from the costs and complexities of planning, purchasing, and maintaining hardware Use Case - Short Term Instances, Spiky Traffic, First Time Applications (Unknown Demand)  Reserved Instances  You can save upto 75% off compared to on-demand instances Reserved instance lock in a reduced rate for one or three years Your commitment incurs costs even if instance aren’t launched Use Case - Long-running, Critical , Known / Understood, and Consistent workload systems  Spot Instances  You can save up to 90% compared to on-demand instances Allow consumption of spare AWS capacity at really reduced rate. Instances are provided to you as long as your bid price is above the spot price, and you only ever pay the spot price. If your bid is exceeded, instances are terminated with two-minute-warning Use Case - Non critical workloads, burst workloads or consistent non-critical workloads that can tolerate interruptions. Not good options for long running jobs that cannot tolerate interruptions.  Savings Plans  Flexible pricing model that offer low price on EC2 or Fargate usage, in exchange for a commitment to a consistent amount of usage (measured in $/hour) for a 1 or 3 year term  Dedicated Hosts  Dedicated host give you complete control over physical instance placement and dedicated hardware free from other customer interactions. Dedicated hosts are generally used when software is licensed per core/CPU and not compatible with running within a shared cloud environment. Can be purchased On-Demand (Hourly)  Amazon Machine Image (AMI)  AMIs are used to build instances. They store snapshot of EBS volume, launch permission and block device mapping that specify the volumes to attach to the instance when it\u0026rsquo;s launched. AMIs are regional service You can create an AMI from existing EC2 instance that are in either running or stopped state Community AMIs are AMIs managed by public (community). These AMI come from AWS users, and are not verified by AWS AWS Marketplace - AMIs verified by AWS. AWS Marketplace consists of both Free as well as paid version of AMIs Two types of AMI  Instance Store Back AMIs - Root Volume doesn\u0026rsquo;t use EBS EBS Backed AMIs - Root Volume uses EBS  AMIs are faster but compared to UserData, AMIs doesn\u0026rsquo;t support dynamic configuration  Amazon Elastic Block Storage (EBS)  Storage service that creates and manages volumes EBS Volumes are durable block level storage device that you can attach to a single EC2 instance Volumes are persistent, can be attached and removed from EC2 instances, and are replicated within a single AZ EBS Snapshots are a point-in-time backup of an EBS volume stored in S3 Snapshots are incremental - The initial snapshot is a full copy of the volume. Future snapshots only store the data changed since the last snapshot Snapshots can be used to create new volumes and are a great way to move or copy instances between AZs. When creating a snapshot of the root volume of an instance of busy volume, it’s recommended the instance is powered off, or disks are “flushed” Snapshots can be copied between regions, shared and automated using Data Lifecycle Manager (DLM) By default, root volumes are deleted on termination Volume encryption uses EC2 host hardware to encrypt data at rest and In-Transit between EBS and EC2 instances  EBS Volume Types  General Purpose SSD (gp2)  Default for most workloads  Provisioned IOPS SSD (io1)  Used for applications that required sustained IOPS performance Ideal for large database workloads  Throughput Optimized HHD (st1)  Low cost volume storage Used for frequently accessed, throughput-intensive workloads (Streaming, BigData) Cannot be root volume  Cold HDD (sc1)  Cheapest volume solution Infrequent accessed data Cannot be root volume   AWS Lambda  Serverless Compute service offering Lambda\u0026rsquo;s are serverless functions. You don\u0026rsquo;t need to manage or provision servers Lambda functions are stateless You choose the amount of memory you want to allocate to your functions and AWS Lambda allocates proportional CPU, Network, Bandwidth and Disk There are 7 runtime languages supported:  Ruby Python Java NodeJS C# Powershell Go  Pricing - Pay per invocation (The duration and the amount of memory used) rounded up to the nearest 100 ms. First 1M requests per month are free You can adjust the duration timeout up to 15 minutes and memory up to 300 MB By default, AWS executes your Lambda function code securely within a VPC. Alternatively you can enable your Lambda function to access resource inside your private VPC by providing additional VPC specific configuration Lambda is HA and scalable by design. Lambda can scale to 1000 os concurrent functions in seconds Lambdas have Cold Starts (delayed Initial Start), if a function has not been recently been executed.  Amazon Elastic Container Service (ECS)  ECS is a managed container service It allows docker containers to be deployed and managed within AWS environments ECS can use infrastructure cluster based on EC2 or Fargate  With EC2 launch type, you own EC2 instances AWS Fargate is a managed service, so tasks are auto placed  Amazon ECS is a regional service Components  Cluster - A logical collection of ECS resources - either ECS EC2 instances or a logical representation of managed Fargate infrastructure Task Definition - Defines your application. Similar to Dockerfile but for running containers in ECS. Task definition can contain multiple containers Container Definition - Inside a task definition, a container definition defines the individual containers a task uses. It controls the CPU and memory each container has, in addition to port mappings for the container Task - A single running copy of any containers defined by a task definition. One working copy of an application Service - Allows task definitions to be scaled by adding additional tasks. Define minimum and maximum values Registry - Storage for container images. (eg. ECS Container Registry or Dockerhub). Used to download image to create containers   Auto Scaling Groups (ASG)  An ASG is a collection of EC2 instances grouped for scaling and management Metrics such as CPU utilization or network transfer can be used either to scale out or scale in using scaling policies Size of an ASG is based on a Min, Max and Desired Capacity (How many EC2 instances you want to ideally run) Auto Scaling Groups are often paired with ELB ASG uses launch configuration or launch template and allow automatic scale-out or scale-in based on configuration metrics Scaling can be Manual, Scheduled or Dynamic Scaling policy can be:  Simple Scaling Policy - Policy triggers a scaling when an alarm is breached Scaling Policy with Steps - New version of Simple Scaling policy and allows you to create steps based on alarm values Target Scaling Policy - Based on when a target value for a metrics is breached. e.g, Average CPU Utilization exceeds 90%  Health checks determine the current state of an instance in the ASG Health checks can be run against either an ELB or the EC2 instances  "
},
{
	"uri": "/02-networking/",
	"title": "02 - VPC Networking",
	"tags": [],
	"description": "",
	"content": "  Virtual Private Cloud (VPC)  VPC Routing Subnets  NAT Gateway Internet Gateway (IGW) VPC Endpoint Security Group (SG) Network Access Control List (NACL) AWS Managed VPN VPC Peering  Virtual Private Cloud (VPC)  A private network within AWS. It lets you provision a logically isolated section of AWS cloud where you can launch AWS resources in a virtual network you define. Can be configured to be public/private or a mixture Regional Service (can’t span regions), highly available, and can be connected to your data center and corporate networks Isolated from other VPCs by default VPC and subnet: Max /16 (65,536 IPs) and minimum /28 (16 IPs) VPC subnet cannot span AZs (1:1 Mapping) Certain IPs are reserved in subnets By default you can create up to 5 VPC per region Default VPC  Required for some AWS services Pre-configured with all required network / security configurations A /20 Public subnet in each AZ, allocating a public P by default Attached internet gateway with a \u0026ldquo;main\u0026rdquo; route table sending all IPv4 traffic to the internet gateway using a 0.0.0.0/0 route   VPC Routing  Every VPC has a virtual routing device called the VPC Router Router interconnects subnet and directs traffic entering and leaving the VPC and it\u0026rsquo;s subnets Router Table is a collection of routes that are used when traffic from a subnet arrives at the VPC Router Every route table has a local route, which matches the CIDR of the VPC and lets traffic be routed between subnets A route contains a destination and a target. Traffic is forwarded to the target if its destination matches the route destination If multiple routes apply, the most specific is chosen. A/32 is chosen before a /24, before a /16 A subnet is a public subnet if it is  (1) configured to allocate public IPs (2) if the VPC has an associated internet gateway (3) if that subnet has a default route to that internet gateway.   Subnets  Public Subnet - If a subnet traffic is routed to Internet Gateway, the subnet is known as a Public Subnet Private Subnet - If the subnet doesn\u0026rsquo;t have a route to Internet Gateway, then the subnet is Private Subnet VPN only Subnet - If the subnet doesn\u0026rsquo;t have route to Internet Gateway, but has it\u0026rsquo;s traffic routed to virtual private gateway for a VPN Subnet map 1 on 1 to AZ\u0026rsquo;s and cannot span AZ  NAT Gateway  NAT (Network Address Translation) is a process where the source or destination address of an IP packets are changed Static NAT is process of 1:1 translation where an internet gateway converts a private address to public IP Address Dynamic NAT is a variation that allows many private IP to get outgoing internet access using smaller number of public IP (generally one) Dynamic NAT is provided within AWS using NAT gateway that allows private subnet in AWS VPC to access the internet NAT Gateway is used to enable instances ina private subnet to connect to the internet or other AWS services, but prevent the internet from initiating a connection with those instances NAT Gateway must be crated within a Public Subnet NAT Gateway is not HA by design. For multi AZ redundancy, create NAT gateway in each AZ with routes for private subnet to use local gateway NAT instances are simply EC2 instances with specially configured routing table  Internet Gateway (IGW)  IG is horizontally scaled, redundant and highly available VPC component that allows communication between instance in your VPC and internet IG serves as:  To provide target in your VPC route table for internet routable traffic To perform NAT translation for instance that have been assigned public Ipv4 address  You cannot have multiple IG for a single VPC  VPC Endpoint  VPC Endpoints are gateway objects created within a VPC. They can be used to connect to AWS public servers without the need for the VPC to have an attached internet gateway and be public. VPC Endpoint Types:  Gateway endpoints: Can be used for DynamoDB and S3 Interface endpoints: Can be used for everything else (e.g. SNS, SQS)  Gateway endpoints are free whereas Interface endpoint cost money Gateway endpoints are HA across AZs in a region Interface endpoint uses and Elastic Network Interface (ENI) with private IP Interface endpoints are interfaces in a specific subnet. For HA, you need to add multiple interfaces - one per AZ  Security Group (SG)  Security group acts like a firewall at the instance level Unless allowed specifically, all inbound traffic is blocked by default All outbound traffic from the instance is allowed by default SGs are Stateful, which means if traffic is allowed inbound it is also allowed outbound EC2 instances can belong to multiple SG Using SG, you cannot block specific IP, SG only supports allow You can have up to 10,000 SG per region You can have 60 inbound and 60 outbound rules per Security Group You can have 16 SG associated to an ENI  Network Access Control List (NACL)  NACLs are collection of rules that explicitly allow or deny traffic based on its protocol, port range, and source/destination (Unlike SG, which can only allow) NACL operate at Layer 4 of the OSI Model (TCP/UDP and below) Each subnet within a VPC must be associated with a NACL NACLs only impact traffic crossing the boundary of a subnet. (If communication occurs within a subnet, no NACLs are involved) Rules are processed in number order, lowest first. When a match is found, that action is taken and processing stops NACLs are stateless NACL can be used to block a single IP (SG cannot perform implicitly deny)  AWS Managed VPN  Virtual Private Network (VPN) provides a software based secure connection between a VPC and On-premise networks Components of VPN  Customer Gateway (CGW) - Configuration for On-Premise Router Virtual Private Gateway attached to VPC VPN Connection   VPC Peering  Allows direct communication between VPCs enabling you to route traffic privately using private IPv4 address or IPv6 address Services can communicate using private IPs from VPC to VPC VPC peers can span AWS accounts and even regions (with some limitations) Data is encrypted and transits via the AWS global backbone VPC peers are used to link two VPCs at layer 3 Ideal use cases for VPC peering - company mergers, shared services, company and vendor, auditing During VPC peering, VPC CIDR blocks cannot overlap Routing across VPC is not transitive NACL and SGs can be used to control access on the VPC peering  "
},
{
	"uri": "/03-storage/",
	"title": "03 - AWS Storage",
	"tags": [],
	"description": "",
	"content": "  Amazon S3  Buckets Versioning Amazon S3 Security Storage Classes S3 Standard S3 Standard Infrequent Access (Standard-IA) S3 One Zone Infrequent Access (OneZone-IA) Amazon S3 Intelligent Tiering Glacier  Glacier Deep Archive  S3 Cross Region Replication (CRR)  Amazon Elastic File System (EFS) AWS Storage Gateway  Amazon S3  Simple Storage Service (S3) is object based Storage Service. Stores unlimited amount of data without worrying about underlying infrastructure S3 replicates data across at least 3 AZ\u0026rsquo;s to ensure 99.99% Availability and 99.99% (11 9\u0026rsquo;s Durability) Objects can be from 0 Bytes up to 5 TB (Multipart Upload). Single PUT upload support up to 5 GB For filesize greater than 100 MB, Multipart Uploads are recommended S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and an S3 bucket. A Presigned URL is a temporary URL that allows users to see assigned S3 objects using the creator’s credentials. Presigned Urls are commonly used to access private objects.  Buckets  S3 stores data as objects within buckets. Buckets can also contain folders which can in turn contain objects Bucket name must be a unique DNS-complaint name  Bucket names are unique across all AWS accounts After you create the bucket you cannot change the name All new buckets are \u0026ldquo;private\u0026rdquo; by default.  Access to S3 buckets are configured using Bucket Policy and Access Control List (ACL). ACLs are legacy mechanism to handle access control  Versioning  Once versioning is turned On, Objects are given a VersionID When a new objects are uploaded the old objects are kept. You can access any object version With versioning enabled, an AWS account is billed for all versions of all objects Object deletions by default do not delete an object - instead a delete marker is added to indicate the object is deleted MFA Delete enforce DELETE operation to require MFA token in order to delete an object. To enable MFA delete, versioning should be turned on Once a bucket is version-enabled, it can never be fully switched off - only suspended.  Amazon S3 Security  As Data in Motion, all the data transfer coming in and out from S3 are encrypted with SSL Data at Rest can be configured per object basis using  AWS Managed Server Side Encryption - (SSE-KMS) - Envelope encryption via AWS KMS and you mange the keys S3 Managed Server Side Encryption - (SSE-AES) - S3 handles the key, uses AES-256 algorithm Client Side Encryption - Client is responsible for managing both encryption / decryption and it\u0026rsquo;s keys   Storage Classes S3 Standard  Default, all purpose storage or when usage is unknown 99.99 (11 nines) Durability and four nines Availability No minimum object size No retrieval fee  S3 Standard Infrequent Access (Standard-IA)  For long-lived, but less frequently accessed data Stores the object data redundantly across multiple geographically separated AZs. (Replicated 3+ AZ) 30 Days and 128 KB minimum charge and object retrieval fee  S3 One Zone Infrequent Access (OneZone-IA)  Less expensive than Standard-IA Data stored in only 1 AZ (99.5% Availability) Ideal for non mission critical and/or reproducible objects 30 Days and 128 KB minimum charge and object retrieval fee  Amazon S3 Intelligent Tiering  Storage class designed for customer who want to optimize storage costs automatically when data access patterns change, without performance impact or operational overhead Automatically move data between Frequent access and infrequent access tiers S3 Intelligent-Tiering monitors access patterns and move objects that have not been accessed for 30 consecutive days to the infrequent access tier.  Glacier  For long-term archival storage (warm and cloud backups) Archived objects are not available for real-time access. You must first restore the objects before you can access them 3+ AZ replication, 90 Days and 40KB minimum charge and retrieval fee  Glacier Deep Archive  Long-term retention of data that is accessed rarely in a year Lowest cost storage 180 Days and 40KB minimum charge and retrieval fee\n Storage Classes can be controlled via Lifecycle Rules, which allow for the automated transition of object between storage classes, or in certain cases allow for the expiration of objects that are no longer required.\n  S3 Cross Region Replication (CRR)  Feature that can be enabled on S3 buckets allowing one-way replication of data from a source bucket to a destination bucket in another region You must have versioning enabled in the source and destination bucket to enable CRR You can have CRR replicate to bucket in another AWS Account Replication requires an IAM role with permission to replicate objects, With the replication configuration, it is possible to override the storage class and object permission as they are written to the destination.  Amazon Elastic File System (EFS)  EFS provides a simple, scalable, fully managed elastic NFS file system for use with AWS Cloud services, and on-premises resource It is a popular shared storage system that can be natively mounted as a file system within Linux instances With EFS, File system can be created and mounted on multiple Linux instances at the same time Amazon EFS offers two storage classes: The Standard storage class, Infrequent Access Storage Class EFS is designed for large scale parallel access of data. Ideal use cases include, Shared media, Logging solutions where various clients need to access Shared Data Amazon EFS is Region Resilient. Security groups are used to control access to NFS mount targets.  AWS Storage Gateway  Hybrid storage service that allows you to migrate data into AWS, extending your on-premises storage capacity using AWS There are three main types of Storage Gateway:  File gateway Volume gateway Tape gateway  A File gateway supports a file interface into AWS S3 and combines a server and a virtual software appliance. Using File gateway, you can store and retrieve objects in Amazon S3 using NFS and SMB Volume Gateway provides cloud-backed storage volumes that you can mount as Internet Small Computer System Interface (iSCSI). The volume gateway is deployed into your on-premises environment as a VM running on VMWare ESXI, KVM or Microsoft Hyper-V hypervisor A tape gateway provides cloud-backed virtual tape storage. The tape gateway is deployed into your on-premises environment as a VM running on VMware ESXi, KVM or Microsoft Hyper-V hypervisor  "
},
{
	"uri": "/04-network-content-delivery/",
	"title": "04 - Network and Content Delivery",
	"tags": [],
	"description": "",
	"content": "  Amazon CloudFront Amazon Route 53 API Gateway AWS Direct Connect AWS Elastic Load Balancers (ELB)  Classic Load Balancers Application Load Balancers Network Load Balancers   Amazon CloudFront  CloudFront is a CDN (Content Delivery Network). It makes website load faster by serving cached content Benefits of using CloudFront includes  Lower Latency Higher Transfer Speed Reduced load on Content Server  Origin is the address of where the original copies of your files reside eg. S3, EC2, ELB Distribution defines a collection of Edge locations and behaviors on how it should handle your cached content Distribution has 2 types: Web Distribution (static website content) and RTMP (streaming media) Edge Locations are local infrastructure that hosts cache of data Origin Identity Access (OAI) is used to access private S3 buckets, restricting S3 bucket access only via Cloud Front Access to cached content can by protected via Signed Urls or Signed Cookies Lambda@Edge allows you to pass each request through a Lambda to change the behavior of the response  Amazon Route 53  Route53 is a DNS provider, register and manage domains, create record sets and health check of resources Simple Routing (Default) - A simple routing policy is a single record within a hosted zone that contains one or more values. When queried a simple routing policy record returns all the values in a randomized order. Weighted Routing - Weighted routing policy can be used to control the amount of traffic that reaches specific resources, based on different \u0026lsquo;weights\u0026rsquo; assigned (Percentages). It can be useful when testing new software or when resources are being added or removed from. Latency Based Routing - Directs traffic based on region, for lowest possible latency for users Failover Routing - Failover routing allows you to create two records with same name. One is designed as the primary and another as secondary. Queries will resolve to the primary - unless it is unhealthy, in which the Route 53 will respond with the secondary. Geolocation Routing - Route traffic based on the geographic location of a requests origin Traffic Flow - Visual editor, for chaining routing policies, can version policy records for easy rollback AWS Alias Record - AWS\u0026rsquo;s smart DNS record, detects changed IPs for AWS resources and adjusts automatically Route53 Resolver - Lets you regionally route DNS queries between your VPC and your on-premise network  API Gateway  Enabled developers to Create, Publish, Maintain, Monitor and secure APIs Api gateway can use other AWS Services With Lambda, API Gateway forms the front facing part of AWS serverless infrastructure Stages allow you to have multiple published version of your API. Eg, staging, QA, prod CORS issues are common with API Gateway, CORS can be enabled on all or individual endpoints With API Gateway, you can use setup cache with customizable keys and TTL for your API data API Gateway is integrated with CloudWatch, so you get backend performance metrics such as API calls, latency, and error rates API Gateway can also log API execution errors to CloudWatch Logs.  AWS Direct Connect  A Direct Connect (DX) is a physical connection between your network and AWS either directly via a cross-connect and customer router at a DX location or DX partner Ideal used for Higher throughput network traffic with low latency  AWS Elastic Load Balancers (ELB)  ELB is a service that provides a set of highly available and scalable load balancers in one of three versions: Classic (CLB), Application (ALB) and Network (NLB) ELBs can be paired with Auto Scaling groups to enhance high availability and fault tolerance - Automating scaling / Elasticity An elastic load balancer has a DNS record, which allows access to the external side ELBs cannot go cross-region. You must create one per region  Classic Load Balancers  CLB use Listeners and EC2 instances are directly registered as targets to CLB Support L3 and L4 (TCP and SSL) and some HTTP/S features Supports 1 SSL certificate per CLB - can get expensive for complex projects Sticky sessions can be enabled for CLB  Application Load Balancers  Operates on L7 of the OSI model ALB has Listeners, Rules and Target Groups to route traffic ALBs are now recommend as the default LB for VPCs. They perform better than CLBs and are most always cheaper. Content rules can direct certain traffic to specific target groups.  Host-based rules: Route traffic based on the host used Path-based rules: Route traffic based on URL path  ALBs support EC2, ECS, EKS, Lambda, HTTPS, HTTP/2 and WebSockets, and they can be integrated with AWS Web Application Firewall (WAF) Sticky sessions can be enabled for ALB   Network Load Balancers  NLB user Listeners and Target Groups to route traffic NLB is for high network throughput applications  "
},
{
	"uri": "/05-database/",
	"title": "05 - AWS Database Services",
	"tags": [],
	"description": "",
	"content": "  Amazon RDS (Relational Database Service)  RDS Multi-AZ RDS Read Replica  Amazon Aurora  Aurora Endpoints Aurora Serverless  DynamoDB  DynamoDB Indexes DynamoDB Streams DynamoDb Performance and Billing  Database Migration Service (DMS)  Amazon RDS (Relational Database Service)  RDS is a Database as a Service (DBaaS) product. It can be used to provision a fully functional database without the admin overhead traditionally associated with DB platforms RDS supports a number of database engines - MySQL, MariaDB, PostgreSQL, Oracle, Microsoft SQL Server, Aurora RDS can be deployed in single AZ or Multi-AZ mode (for resilience) and supports General purpose and Memory Optimized instances RDS instances are managed by AWS, you cannot SSH into the VM instances Primary use case for RDS are Relational, Transactional databases. Best for relational datastore requirements (OLTP) By default, Customer are allowed to have up to 40 RDS databases Pricing - RDS instances are charged based on  Instance Size Provisioned storage (Not Used) IOPS (io1) Data Transfer Out Any backups/snapshots beyond the 100% total database storage for a region  RDS Supports encryption  Encryption can be configured when creating DB instances Encryption can be added by taking a snapshot, making an encrypted snapshot, and creating a new encrypted instance from that encrypted snapshot Once encrypted, encryption cannot be removed  Automated backups to S3 occur daily and can be retained from 0 to 35 days. (0 means disabled) Manual snapshot are taken manually and exist until deleted, and point-in-time log-based backups are also stored on S3  RDS Multi-AZ  RDS can be provisioned in Single or Multi-AZ mode. Multi-AZ makes an exact copy of your data in another AZ Multi-AZ provisions a primary instance and a standby instance in a different AZ of the same region With MultiAZ you do not have access to secondary AZ Multi-AZ has Automatic Failover protection if one AZ goes down, failover will occur and the standby will be promoted to primary  RDS Read Replica  RDS Read Replicas are read-only copies of an RDS instance that can be created in the same region or a different region from the primary instance Read Replicas can be addressed independently (each having their own DNS name) and used for read workloads, allowing you to scale reads 5 Read Replicas can be created from a RDS instance, allowing a 5x increase in reads Unlike Multi-AZs, read replicas can be used across regions. They also can be within the same AZ or even across AZs The primary instance needs to have automatic backups enabled to use Read Replicas With read replicas, AWS takes care of the networking aspects needed for asynchronous syncing between the primary and secondary regions Read replica use cases  When needing a faster recovery time than restoration from a snapshot When most of your DB usage is reading rather than writing, you can scale out your datbase instances for read-only purpose. (Horizontal Scaling) Have a Global Resilience   Amazon Aurora  Amazon Aurora is a fully-managed, MySQL-compatible, relational database engine that combines the speed and availability of high-end commercial databases that needs to scale, with Automatic backups, high availability, and fault tolerance Aurora MySQL is 5x faster over regular MySQL and 3x faster over regular Postgres Aurora is 1/10th the cost over its competitors with similar performance and availability options Aurora uses a base configuration of a cluster, which consists of one more db instances and a cluster volume that spans multiple AZs, with each AZ having a copy of the db cluster data A cluster contains a single primary instance and zero or more replicas Aurora cluster volume automatically scale as the amount of data in your database increases, up to max of 64 TB AWS Aurora only bills for the consumed data, and it\u0026rsquo;s constantly backed up to S3 Aurora replicates 6 copies of your database across 3 availability zones (2 Copies of data are kept in each AZ with minimum of 3 AZ) Aurora Serverless  Aurora Endpoints  Cluster endpoint - Connects to the primary db instance for the db cluster. This endpoint is the one that can perform write operation Reader endpoint - Connects to the one of the available Aurora replicas for the database cluster Custom endpoint - Represents a set of database instances that you choose. When you connect to the endpoint, Aurora performs load balancing and chooses one of the instance in the group to handle the connection. Instance endpoint - Connects to a specific database instance within an Aurora cluster. The instance endpoint provides direct control over connections to the db cluster.  Aurora Serverless  On-demand, auto-scaling configuration for Amazon Aurora (MySQL-compatible and PostgreSQL-compatible editions) The database will automatically start up, shut down, and scale capacity up or down based on your application\u0026rsquo;s needs It\u0026rsquo;s a simple, cost-effective option for infrequent, intermittent, or unpredictable workloads Enabled you to run database in cloud without managing any database instances Pricing is based on per-second for the database capacity you use when the database is active  DynamoDB  DynamoDB is a fully managed NoSQL key/value and document database that provides fast and precedable performance with seamless scalability It’s a regional service, partitioned regionally and allows the creation of tables, hence tables names in DynamoDB have to be regionally unique DynamoDB can be set to have Eventual Consistent Reads (default) and Strongly Consistent Reads Eventual consistent reads data is returned immediately but data can be inconsistent. Strongly Consistent Reads will wait until data is consistent DynamoDb stores 3 copies of data on SSD drive across 3 regions Key Components  A Table is a collection of items that share the same partition key (PK) or partition key and sort key(SK) together with other configuration and performance settings An Item is a collection of attributes (up to 400 KB in size) inside a table that shares the same key structure as every other items in the table Attribute is a fundamental data element which consists of key and value Primary Key is a unique identifier for the items in the table Partition Key and Sort Key is composed of two of more attributes Secondary Indexes allows you to query the data in the table using the alternate key   DynamoDB Indexes  Indexes provide an alternative representation of data in a table, which is useful for application with varying query demands Indexes come in two forms: Local Secondary Indexes (LSI) and Global Secondary Indexes (GSI) Indexes are interacted with as though they are table, but they are just an alternate representation of data in an existing table There are two types of Secondary Indexes  Global Secondary Index (GSI) - An index with a partition key and sort key that can be different from that on the table Local Secondary Index (LSI) - An index that has the same partition key as the table, but a different sort key  LSIs must be created at the time of creation of table. GSI can be created at any point after the table is created. You can define up to 20 GSI and 5 LSI per table  DynamoDB Streams  When enabled, streams provide an ordered list of changes that occur to items within a DynamoDB table A stream is a rolling 24-hour window of changes Streams are enabled per table and only contain data from the point of being enabled. Streams can be configured with one of four view types:  KEYS_ONLY - Whenever an item is added, updated or deleted, the key(s) of that item are added to the stream. NEW_IMAGE - The entire item is added to the stream “post-change” OLD_IMAGE - The entire item is added to the stream “pre-change” NEW_AND_OLD_IMAGES - Both the new and old versions of the items are added to the stream.  Streams can be integrated with AWS Lambda, invoking a function whenever items are changed in a DynamoDB table (a DB trigger)  DynamoDb Performance and Billing  DynamoDB has two read/write capacity modes: Provisioned throughput (default) and On-Demand mode When using On-Demand mode, DynamoDB automatically scales to handle performance demands and bills a per-request charge When using Provisioned throughput mode, each table is configured with read capacity units (RCU) and write capacity units (WCU)  Database Migration Service (DMS)  DMS is a service to migrate relational database, To and From from any location with network connectivity to AWS DMS is compatible with a broad range of DB Sources, including Oracle, MS SQL, MySQL, MariaDB, PostgreSQL, MongoDB, Aurora, and SAP Data can be synced to most of the above engines, as well as Redshift, S# and DynamoDB DMS is useful in a number of common scenarios:  Scaling database resources up and down without downtime Migrating databases from on-premises to AWS, from AWS to on-premises or to/from other cloud platforms Moving data between different DB engines, including schema conversion Partial / subset data migration Migration with little to no admin overhead, as a service   "
},
{
	"uri": "/06-analytics/",
	"title": "06 - Analytics",
	"tags": [],
	"description": "",
	"content": "  Amazon Athena Amazon EMR Amazon Kinesis  Kinesis Data Stream Kinesis Data Firehose Kinesis Data Analytics Kinesis Video Analytics   Amazon Athena  Amazon Athena is an interactive query service that utilizes Schema-On-Read, allowing you to run ad-hoc SQL like queries on data from a range of sources Athena is used to query large dataset (structured, semi-structured, and unstructured) stored in S3 with infrequent access pattern You are charged for compute time only. You don’t need to maintain separate dataset for Athena, it can directly access S3 bucket  Amazon EMR  EMR is tool for large-scale parallel processing of big data and other large data workloads It is based on the Apache Hadoop framework and is delivered as a managed cluster using EC2 instances It is used for huge-scale log analysis, indexing, machine learning, financial analysis, simulations, bio-informatics and many other large-scale applications EMR cluster have zero or more core nodes, which are managed by the master node. They run tasks and manage data for HDFS Data can be input from and output to S3. Intermediate data can be stored using HDFS in the cluster or EMRFS using S3.  Amazon Kinesis  Streaming service designed to ingest large amounts of data from hundreds, thousands or even millions of producers Scalable and Resilient Consumers can access a rolling window of that data, or it can be stored in persistent storage of database products  Kinesis Data Stream  A Kinesis data stream can be used to collect, process, and analyze a large amount of incoming data Storage for all incoming data within a 24 hour default window, which can be increased to seven days for an additional charge Kinesis Data records (The basis entity written to and read from Kinesis stream, a data record can be up to 1 MB in size) are added by producers and read by consumers  Kinesis Data Firehose  Reliably load streaming data into data lakes, data stores and analytics tools It can capture, transform, and load streaming data into Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, and Splunk It enables near real-time analytics with existing business intelligence tools and dashboards you’re already using today Kinesis Data Streams can be used as the source(s) to Kinesis Data Firehose Pay for only the data ingested   Kinesis Data Analytics  Process and analyze real-time, streaming data Can use standard SQL queries to process Kinesis data streams A Kinesis Data Analytics application consists of three components:  Input – the streaming source for your application Application code – a series of SQL statements that process input and produce output Output – one or more in-application streams to hold intermediate results   Kinesis Video Analytics  Securely ingests and stores video and audio encoded data to consumers such as SageMaker, Rekognition or other services to apply Machine Learning and Video processing  "
},
{
	"uri": "/07-application-integration/",
	"title": "07 - Application Integration",
	"tags": [],
	"description": "",
	"content": "  Amazon Simple Notification Service (SNS) Amazon Simple Queue Service (SQS) AWS Step Functions   Amazon Simple Notification Service (SNS)  SNS is a fully managed pub/sub messaging service Topics are logical access point and communication channel within SNS Topics can be encrypted via KMS Subscribers are endpoints that receive message for topic. When a topic received a message it automatically and immediately pushes messages to subscribers SNS supports notification over multiple protocols:  HTTP/HTTPS - Subscribers specify a URL as part of the subscription registration Email/Email Json - Messages are sent to registered address as email SQS - User can specify an SQS standard queue as the endpoint SMS - Messages are sent to registered phone number as SMS text messages   Amazon Simple Queue Service (SQS)  SQS provides fully managed, highly available message queuing service for inter-process /service /service messaging SQS is used for application integration, it lets decouple different systems SQS supports both Standard and FIFO Queues Standard queues are distributed and scalable to nearly unlimited message volume. The order is not guaranteed, best-effort only, and messages are guaranteed to be delivered at least once but sometimes more than once. FIFO queues ensure first-in,first-out delivery. Messages are delivered once only - duplicates do not occur. The throughput is limited to ~ 3,000 messages per second with batching or ~300 without by default. There are two types of polling  Short Polling - Available messages are returned immediately, even if the message queue being polled is empty Long Polling - Waits for message for a given WaitTimeSeconds (More Efficient)  Each SQS message can contain up to 256KB of data but can link data stored in S3 for any larger payloads Visibility time-out is the period of time that messages are invisible in the SQS queue Messages will be deleted from queue after a job has processed When a message is polled, it is hidden in the queue. It can be deleted when processing is completed - otherwise, after a VisibilityTimeout period, it will return to the queue The default Visibility time-out is 30 seconds. Timeout can be 0 seconds to a maximum of 12 hours. Retention period of SQS can be from 60 seconds to 14 days (Default is 4 Days) Message size is between 1 byte to 256 kB, Extended Client Library for Java can increase to 2 GB  AWS Step Functions  Step Functions are Serverless visual workflow service that provides state machines A state machine can orchestrate other AWS services with simple logic, branching, and parallel execution, and it maintains a state Workflow steps are known as states, and they can perform work via tasks State machines maintain state and allow longer running processes.  "
},
{
	"uri": "/08-hybrid-scaling/",
	"title": "08 - Hybrid and Scaling",
	"tags": [],
	"description": "",
	"content": "  Snowball and Snowball Edge Snowmobile  Snowball and Snowball Edge  Snowball and Snowball Edge is a rugged container which contains a storage device It is used to move large amount of data quickly in and out of AWS. You can both export or import data using Snowball or Snowmobile Snowball and Snowball Edge is peta-scale migration; Snowmobile is for exabyte-scale migration Snowball comes in two sizes:  50 TB (42 TB of usable space) 80 TB (72 TB of usable space)  Snowball Edge comes in two sizes:  100 TB (83 TB of usable space) 100 TB Clustered (45 TB per node)  Snowball Edge includes both Storage and edge-computing workloads Snowball Edge provides three options  Edge Storage Optimized (24 vCPU) Edge Compute Optimized (52 vCPU)) Edge Compute Optimized with GPU  Snowball and Snowball Edge are idea for data transfer from 10 TB to 10 PB of data transfer  Snowmobile  It is 45 foot long ruggedize shipping container, pulled by a semi-trailer truck Snowmobile comes in one size: 100 PB Available in certain areas via special order from AWS Ideal for greater than 10PB Data Transfer for a single location Situated on side and connected into your data center for the duration of the transfer  "
},
{
	"uri": "/",
	"title": "AWS Solutions Architect Associate Notes",
	"tags": [],
	"description": "",
	"content": "  01 - AWS Compute Services   02 - VPC Networking   03 - AWS Storage   04 - Network and Content Delivery   05 - AWS Database Services   06 - Analytics   07 - Application Integration   08 - Hybrid and Scaling   Resources   "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/resources/",
	"title": "Resources",
	"tags": [],
	"description": "",
	"content": " AWS Well-Architected Amazon Elastic Compute Cloud Documentation Introduction to AWS Lambda \u0026amp; Serverless Applications  "
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]